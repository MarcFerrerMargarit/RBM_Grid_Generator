{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROBLEM DESCRIPTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we want to analyze is styles from a group of elements. In this case we had 4 styles so we want at least one machine for every one that it will be able to analyze the data an generate new data.\n",
    "\n",
    "So the data that we have is a set of vectors that's the output of the app that generate grids. This grids ara a composition of elements so the outuput will be a vector of id. Each grid had 48 elements and each element can have a maximum of 255 elements in it. But is not necessary to had that number, it can be possible to have less. \n",
    "\n",
    "<h4 align=\"center\">$[ x_1, x_2, x_3, ..., x_{48} ]$</h4> \n",
    "<h4 align=\"center\">$x_1 = [id_1,id_2,_id_3, ...,id_{255}]$</h4>\n",
    "\n",
    "Each element of the vector can have a different size from the others and the list of integers are the subcategories of style of the object that was placed in the grid. Each number is a different subcategory of style of the object placed previously.\n",
    "\n",
    "So the first objective is to descompose the input data, a vector which element is a vector of different size, to a list of vectors that will have de same length, 48, and one element in each position. So the main goal is to find the grid wich elements has more IDs so we can set the size of total vectors,$y$, that we need to descompose the data. In case that one element of the vector has lower IDs that the max we gonna put a $0$ as the null value for our data.\n",
    "\n",
    "<h4 align=\"center\">$input = [[id_1^1,id_2^1,_id_3^1, ...,id_{255}^1], [id_1^2,id_2^2,_id_3^2, ...,id_{255}^2], ..., [id_1^{48},id_2^{48},_id_3^{48}, ...,id_{255}^{48}]]$</h4> \n",
    "<h4 align=\"center\">$output = [[id_1^1, id_1^2,..., id_1^{48}],\n",
    "[id_2^1, id_2^2,..., id_2^{48}],..., [0,0,...,id_y^{48}]$</h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent =  currentdir + '\\RBM'\n",
    "sys.path.insert(0,parent)\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numexpr  as ne\n",
    "import profile\n",
    "import rbm as Rbm\n",
    "import pandas\n",
    "from random import randint\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "import Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In the file *Utils.py* we have 2 two functions that allow us to transform our input data. \n",
    "\n",
    "The first one is *getMaxLengthForElements*. This functions returns a integer that specifies the max length that the vectors must have after analyzing all the input vectors.\n",
    "\n",
    "\n",
    "The second one is *transformInputVector*. This function transform the input data by transforming each vector to the maximum length and adding $0$ to the vectors who had less length than the maximum.\n",
    "\n",
    "\n",
    "Applying this 2 functions we can transform our data to be processed and converted to one hot vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6528, 48)\n"
     ]
    }
   ],
   "source": [
    "vector_data = pd.read_json('./Data.json')\n",
    "A = vector_data.values\n",
    "data_modern = []\n",
    "A = A.ravel()\n",
    "length_vectors = len(A)\n",
    "for i in range(A.shape[0]):\n",
    "    len_v = len(A[i])\n",
    "    tmp = []\n",
    "    for j in range(len_v):\n",
    "        tmp.append(A[i][j])\n",
    "    tmp = np.asarray(tmp).ravel()\n",
    "    data_modern.append(tmp)\n",
    "data_modern = np.asarray(data_modern)\n",
    "input_data = []\n",
    "input_data.append(data_modern)\n",
    "input_data = np.asarray(input_data)\n",
    "max_elements = Utils.getMaxLengthForElements(input_data[0])\n",
    "f_data = Utils.transformInputVector(input_data[0], max_elements, length_vectors)\n",
    "\n",
    "#Multiply data for obtain more range <= 10000.\n",
    "for i in range(50):\n",
    "    for k in range((length_vectors*max_elements)):\n",
    "        f_data.append(f_data[k])\n",
    "f_data = np.asarray(f_data)\n",
    "print(f_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this poing we have the data formatted ready for the input for the machine. In this case we gonna use the algorithm of the library sklearn, BernoulliRBM. Also we gonna use the implementation of One Hot Vector to transform our data to One Hot Vectors.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.BernoulliRBM.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "\n",
    "Now the first step to get the data in the machine is to convert all the data we formatted to one hot vectors. A one hot vector is a vector which is is a group of bits among which the legal combinations of values are only those with a single high (1) bit and all the others low (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oneHotEncoder = OneHotEncoder(262, sparse=True).fit(f_data)\n",
    "oneHotData = oneHotEncoder.transform(f_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have 3 hot vectors which one represents the previous input data. This is a sparse matrix so is fastest to work than a simple vector and it's easy to show the results.\n",
    "Then we neeed to define the parameters of the machine and fit it with de one hot vectors we had. The parameters are not specified, so we need to try whichc are the best to obtain good results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -2536.59, time = 11.25s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -2149.61, time = 11.06s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -2060.71, time = 12.07s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -1686.45, time = 11.16s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -1184.61, time = 11.06s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -898.52, time = 11.69s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -731.96, time = 10.62s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -671.00, time = 11.49s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -610.50, time = 10.89s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -545.41, time = 10.80s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -458.54, time = 10.85s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -356.30, time = 11.39s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -255.24, time = 12.47s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -154.78, time = 11.84s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -55.20, time = 11.11s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -47.50, time = 11.21s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -48.44, time = 11.07s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -47.36, time = 10.44s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -46.73, time = 10.84s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -48.59, time = 10.86s\n",
      "Wall time: 3min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RBM_Machine = BernoulliRBM(n_components=262, learning_rate=0.01,batch_size=64, n_iter=20, random_state=0, verbose=True)\n",
    "RBM_Machine.fit(oneHotData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we got the output. We gonna make as much as the maximum length of samples. Then we gonna format this data and save it to a json in our folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[218, 205, 229, 252, 14, 220], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [8, 4, 12, 4, 121], [246, 13, 7], [237, 115], [245, 219, 176, 246, 177, 127, 219], [219, 14, 176, 232, 166], [0], [0], [199, 57], [218], [9, 239, 183], [254, 130, 219, 14], [8, 218, 176], [176, 128, 155, 218, 218], [218, 212], [245], [0], [154, 219, 218, 219, 154, 254, 154], [253, 219, 136], [109, 218], [0], [0], [245], [219, 218]]\n"
     ]
    }
   ],
   "source": [
    "final_output = []\n",
    "for i in range(16):\n",
    "    x_visible = RBM_Machine.gibbs(oneHotData[random.randint(0,oneHotData.shape[0])])\n",
    "    x_visible = x_visible.ravel()\n",
    "    final_vector = []\n",
    "    for k in range(len(x_visible)):\n",
    "        if(x_visible[k] == True):\n",
    "            final_vector.append(1)\n",
    "        else:\n",
    "            final_vector.append(0)\n",
    "    final_Data = []\n",
    "    for i in range(48):\n",
    "        tmp = final_vector[(262*i):((i+1)*262)]\n",
    "        if(1 not in tmp):\n",
    "            index = 0\n",
    "        else:\n",
    "            index = tmp.index(1)\n",
    "        final_Data.append(index)\n",
    "    final_output.append(final_Data)\n",
    "final_output = np.asarray(final_output)\n",
    "final_data_output = []\n",
    "pos = 0\n",
    "for k in range(48):\n",
    "    t = []\n",
    "    for i in range(len(final_output)):\n",
    "        t.append(final_output[i][k])\n",
    "    final_data_output.append(t)\n",
    "final_data_output = np.asarray(final_data_output)\n",
    "output_grid = []\n",
    "for i in range(48):\n",
    "    v = final_data_output[i].tolist()\n",
    "    v_filter = list(filter((0).__ne__,v))\n",
    "    if(len(v_filter) == 0):\n",
    "        v_filter.append(0)\n",
    "    output_grid.append(v_filter)\n",
    "print(output_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14, 205, 218, 220, 229, 252], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [4, 8, 12, 121], [7, 13, 246], [115, 237], [127, 176, 177, 219, 245, 246], [14, 166, 176, 219, 232], [0], [0], [57, 199], [218], [9, 183, 239], [14, 130, 219, 254], [8, 176, 218], [128, 155, 176, 218], [212, 218], [245], [0], [154, 218, 219, 254], [136, 219, 253], [109, 218], [0], [0], [245], [218, 219]]\n"
     ]
    }
   ],
   "source": [
    "final_output_grid = Utils.cleaningOutput(output_grid)\n",
    "print(final_output_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs, json \n",
    "b = final_output_grid\n",
    "json_file = \"./output_grid.json\" \n",
    "json.dump(b, codecs.open(json_file, 'w', encoding='utf-8'), sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OTHER IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oneHotEncoder = OneHotEncoder(262, sparse=False).fit(f_data)\n",
    "oneHotData = oneHotEncoder.transform(f_data)\n",
    "test_Data_Vector_Aux = np.array(oneHotData, dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visible_dim = oneHotData.shape[1]\n",
    "hidden_dim = 500\n",
    "epochs = 100\n",
    "K = 1\n",
    "lr = 0.1\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rbm_ = Rbm.RBM(visible_dim=visible_dim,\n",
    "               hidden_dim=hidden_dim,\n",
    "               seed=42,\n",
    "               mu=0, \n",
    "               sigma=0.3,\n",
    "               monitor_time=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tepoch: 0 \ttime per epoch: 29.73\ttotal time: 29.73\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c7398d0359b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rbm_.fit(test_Data_Vector_Aux, \\n         method='vectorized_CDK',\\n         K=1,\\n         lr=0.01,\\n         epochs=20,\\n         batch_size=64,\\n         plot_weights=False)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\mferrer\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2116\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2117\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2118\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-61>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mferrer\\Anaconda3\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mferrer\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'eval'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1181\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1182\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mferrer\\Documents\\RBM_Grid_Generator\\RBM\\rbm.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, method, K, lr, epochs, batch_size, plot_weights, folder_plots)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_epochs_trained\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mferrer\\Documents\\RBM_Grid_Generator\\RBM\\rbm.py\u001b[0m in \u001b[0;36mfit_minibatch\u001b[1;34m(self, Xbatch, method, lr, K)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'vectorized_CDK'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_vectorizedCDK\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXbatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mXbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'persistent_CDK'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mferrer\\Documents\\RBM_Grid_Generator\\RBM\\rbm.py\u001b[0m in \u001b[0;36mupdate_vectorizedCDK\u001b[1;34m(self, Xbatch, lr, K)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0mEhn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXneg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m         \u001b[0mDelta_W\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEhp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXneg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEhn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[0mDelta_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mXbatch\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mXneg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[0mDelta_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mEhp\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mEhn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rbm_.fit(test_Data_Vector_Aux, \n",
    "         method='vectorized_CDK',\n",
    "         K=1,\n",
    "         lr=0.01,\n",
    "         epochs=20,\n",
    "         batch_size=64,\n",
    "         plot_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[245, 218, 218, 247, 121, 205, 205, 4, 220, 121, 245, 248, 4, 247], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [219, 6, 10, 246, 6, 14, 218, 13, 6, 4], [12, 7, 7, 12, 12, 218, 7, 218, 4], [218, 218, 14, 218, 245, 14, 12, 245, 14, 4], [218, 183, 218, 183, 177, 176, 218, 183, 219, 154], [177, 6, 14, 245, 213, 176, 14, 239, 6, 237, 245, 234, 8, 218], [46, 87, 10, 13, 46], [218, 176, 138, 219, 218, 237, 40, 246, 31], [246, 218, 218, 237, 10, 12, 12, 237, 10, 4], [218, 6, 218, 4, 219, 14, 219, 6, 198], [9, 9, 218, 183, 14, 14, 246], [219, 8, 219, 237, 8, 10, 218, 8, 7], [177, 177, 9, 177, 218, 177, 177, 176], [219, 219, 40, 14, 14, 218, 40, 155], [197, 218, 197, 218, 14, 237, 197], [13, 218, 13, 219, 219, 245, 13, 246, 198], [219, 9, 206, 9, 218, 207, 246, 9, 246, 135], [245, 245, 219, 202, 202, 154, 176, 240, 202, 8], [13, 13, 13, 202, 210, 13, 136], [219, 14], [136, 9, 218, 248, 14], [219, 248, 219], [12, 176, 246, 176, 14, 240, 176, 4], [253, 7, 7, 218, 120, 245, 7, 4]]\n"
     ]
    }
   ],
   "source": [
    "final_output = []\n",
    "for i in range(100):\n",
    "    x_visible, x_h = rbm_.sample_visible_from_visible(oneHotData[random.randint(0,oneHotData.shape[0])])\n",
    "    x_visible = x_visible.ravel()\n",
    "    final_vector = []\n",
    "    for k in range(len(x_visible)):\n",
    "        if(x_visible[k] == True):\n",
    "            final_vector.append(1)\n",
    "        else:\n",
    "            final_vector.append(0)\n",
    "    final_Data = []\n",
    "    for i in range(48):\n",
    "        tmp = final_vector[(262*i):((i+1)*262)]\n",
    "        if(1 not in tmp):\n",
    "            index = 0\n",
    "        else:\n",
    "            index = tmp.index(1)\n",
    "        final_Data.append(index)\n",
    "    final_output.append(final_Data)\n",
    "final_output = np.asarray(final_output)\n",
    "final_data_output = []\n",
    "for k in range(48):\n",
    "    t = []\n",
    "    for i in range(len(final_output)):\n",
    "        t.append(final_output[i][k])\n",
    "    final_data_output.append(t)\n",
    "final_data_output = np.asarray(final_data_output)\n",
    "output_grid = []\n",
    "for i in range(48):\n",
    "    v = final_data_output[i].tolist()\n",
    "    v_filter = list(filter((0).__ne__,v))\n",
    "    if(len(v_filter) == 0):\n",
    "        v_filter.append(0)\n",
    "    output_grid.append(v_filter)\n",
    "print(output_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 121, 205, 218, 220, 245, 247, 248], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [4, 6, 10, 13, 14, 218, 219, 246], [4, 7, 12, 218], [4, 12, 14, 218, 245], [154, 176, 177, 183, 218, 219], [6, 8, 14, 176, 177, 213, 218, 234, 237, 239, 245], [10, 13, 46, 87], [31, 40, 138, 176, 218, 219, 237, 246], [4, 10, 12, 218, 237, 246], [4, 6, 14, 198, 218, 219], [9, 14, 183, 218, 246], [7, 8, 10, 218, 219, 237], [9, 176, 177, 218], [14, 40, 155, 218, 219], [14, 197, 218, 237], [13, 198, 218, 219, 245, 246], [9, 135, 206, 207, 218, 219, 246], [8, 154, 176, 202, 219, 240, 245], [13, 136, 202, 210], [14, 219], [9, 14, 136, 218, 248], [219, 248], [4, 12, 14, 176, 240, 246], [4, 7, 120, 218, 245, 253]]\n"
     ]
    }
   ],
   "source": [
    "final_output_grid = Utils.cleaningOutput(output_grid)\n",
    "print(final_output_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = output_grid\n",
    "json_file = \"./output_grid_2.json\" \n",
    "json.dump(b, codecs.open(json_file, 'w', encoding='utf-8'), sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Evaluation Quantitativa\n",
    "\n",
    "Evaluar models generatius és en general molt complicat.\n",
    "\n",
    "Per a decidir que el nostre sistema ¨va bé¨ (va millor que generar coses aleatoriament). S´ha decidit generar\n",
    "\n",
    "- 25 dades amb la RBM. \n",
    "- 25 dades aleatories.\n",
    "\n",
    "Donem les graelles al expert i li preguntem quines son bones i quines no. Contem quantes \"de les bones\" corresponnen amb les generades per la RBM.\n",
    "\n",
    "#### Evaluacio custom\n",
    "\n",
    "Podriem mirar de les graelles generades si els objectes son de color similar.\n",
    "\n",
    "###  Evaluation Qualitativa\n",
    "\n",
    "Posar en el document les graelles generades per la RBM, alguna graella random i alguna graella original. Explicar quins aspectes son bons i quins dolents de les graelles generades. Per exemple, demanar al expert que, de les graelles RBM generades quines coses 'no li agraden'.\n",
    "\n",
    "### Posar imatge de la eina\n",
    "\n",
    "Interficie grafica de la imatge.\n",
    "\n",
    "- Que ap\n",
    "orta la eina\n",
    "- Temps que triguen els humans a generar una graella amb photoshop\n",
    "- Temps que triguen els humans a generar una graella amb eina\n",
    "- Temps que triguen els humans a generar una graella amb RBM\n",
    "    - Podries vendre-ho com una \"help tool\" que a un disenyador li genera 25 graelles i ell sols ha de triar\n",
    "      quina li agrada més. I si vol variar alguna cosa de la graella.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
